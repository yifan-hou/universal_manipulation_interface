{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from typing import Dict, Callable, Tuple, List\n",
    "\n",
    "SCRIPT_PATH = \"/home/yifanhou/git/universal_manipulation_interface/scripts\"\n",
    "sys.path.append(os.path.join(SCRIPT_PATH, '../'))\n",
    "\n",
    "# # use line-buffering for both stdout and stderr\n",
    "# sys.stdout = open(sys.stdout.fileno(), mode='w', buffering=1)\n",
    "# sys.stderr = open(sys.stderr.fileno(), mode='w', buffering=1)\n",
    "\n",
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pathlib\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset, BaseDataset\n",
    "from diffusion_policy.common.pytorch_util import dict_apply\n",
    "\n",
    "# allows arbitrary python code execution in configs using the ${eval:''} resolver\n",
    "OmegaConf.register_new_resolver(\"eval\", eval, replace=True)\n",
    "\n",
    "temp_output_dir = \"./temp_output_dir\"\n",
    "\n",
    "with initialize(\n",
    "    version_base=None,\n",
    "    config_path=str('../diffusion_policy/config'),\n",
    "    job_name=\"test_app\"\n",
    "):\n",
    "    print(\"Test Script: starting.\")\n",
    "    cfg = compose(config_name=\"train_diffusion_unet_timm_flip_up_workspace\")\n",
    "    # resolve immediately so all the ${now:} resolvers\n",
    "    # will use the same time.\n",
    "    print(\"Test Script: resolving config.\")\n",
    "    OmegaConf.resolve(cfg)\n",
    "\n",
    "    print(\"Test Script: initializing workspace.\")\n",
    "    cls = hydra.utils.get_class(cfg._target_)\n",
    "    workspace: BaseWorkspace = cls(cfg)\n",
    "    policy = workspace.model\n",
    "\n",
    "    # configure dataset\n",
    "    print(\"Test Script: configuring dataset.\")\n",
    "    dataset: BaseImageDataset\n",
    "    dataset = hydra.utils.instantiate(cfg.task.dataset)\n",
    "    assert isinstance(dataset, BaseImageDataset) or isinstance(dataset, BaseDataset)\n",
    "    print(\"Test Script: Creating dataloader.\")\n",
    "    train_dataloader = DataLoader(dataset, **cfg.dataloader)\n",
    "    print('train dataset:', len(dataset), 'train dataloader:', len(train_dataloader))\n",
    "\n",
    "    # compute normalizer on the main process and save to disk\n",
    "    print(\"Test Script: Computing normalizer.\")\n",
    "    sparse_normalizer_path = os.path.join(temp_output_dir, 'sparse_normalizer.pkl')\n",
    "    dense_normalizer_path = os.path.join(temp_output_dir, 'dense_normalizer.pkl')\n",
    "    sparse_normalizer, dense_normalizer = dataset.get_normalizer()\n",
    "    policy.set_normalizer(sparse_normalizer, dense_normalizer)\n",
    "\n",
    "    device = policy.device\n",
    "    print(\"Test Script: done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reach one batch of data from the dataloader\n",
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "print(batch.keys())\n",
    "for key, attr in batch['obs']['sparse'].items():\n",
    "    print(\"   obs.sparse.key: \", key, attr.shape)\n",
    "for key, attr in batch['obs']['dense'].items():\n",
    "    print(\"   obs.dense.key: \", key, attr.shape)\n",
    "for key, attr in batch['action'].items():\n",
    "    print(\"   action.key: \", key, attr.shape)\n",
    "\n",
    "nobs_sparse = sparse_normalizer.normalize(batch['obs']['sparse'])\n",
    "nactions_sparse = sparse_normalizer['action'].normalize(batch['action']['sparse'])\n",
    "nactions_dense = dense_normalizer['action'].normalize(batch['action']['dense'])\n",
    "\n",
    "batch = dict_apply(batch, lambda x: x.to(device, non_blocking=True))\n",
    "\n",
    "# compute loss\n",
    "raw_loss = policy(batch)\n",
    "print(raw_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def log_action_mse(step_log, category, pred_action, gt_action):\n",
    "    B, T, _ = pred_action['sparse'].shape\n",
    "    pred_action_sparse = pred_action['sparse'].view(B, T, -1, 9)\n",
    "    gt_action_sparse = gt_action['sparse'].view(B, T, -1, 9)\n",
    "    step_log[f'{category}_sparse_action_mse_error'] = torch.nn.functional.mse_loss(pred_action_sparse, gt_action_sparse)\n",
    "    step_log[f'{category}_sparse_action_mse_error_pos'] = torch.nn.functional.mse_loss(pred_action_sparse[..., :3], gt_action_sparse[..., :3])\n",
    "    step_log[f'{category}_sparse_action_mse_error_rot'] = torch.nn.functional.mse_loss(pred_action_sparse[..., 3:9], gt_action_sparse[..., 3:9])\n",
    "    # step_log[f'{category}_sparse_action_mse_error_width'] = torch.nn.functional.mse_loss(pred_action_sparse[..., 9], gt_action_sparse[..., 9])\n",
    "    B, T, _, _= pred_action['dense'].shape\n",
    "    pred_action_dense = pred_action['dense'].view(B, T, -1, 9)\n",
    "    gt_action_dense = gt_action['dense'].view(B, T, -1, 9)\n",
    "    step_log[f'{category}_dense_action_mse_error'] = torch.nn.functional.mse_loss(pred_action_dense, gt_action_dense)\n",
    "    step_log[f'{category}_dense_action_mse_error_pos'] = torch.nn.functional.mse_loss(pred_action_dense[..., :3], gt_action_dense[..., :3])\n",
    "    step_log[f'{category}_dense_action_mse_error_rot'] = torch.nn.functional.mse_loss(pred_action_dense[..., 3:9], gt_action_dense[..., 3:9])\n",
    "    # step_log[f'{category}_dense_action_mse_error_width'] = torch.nn.functional.mse_loss(pred_action_dense[..., 9], gt_action_dense[..., 9])\n",
    "                \n",
    "# sample trajectory from training set, and evaluate difference\n",
    "gt_action = batch['action']\n",
    "pred_action = policy.predict_action(batch['obs'])\n",
    "print(\"gt_action['sparse'].shape: \", gt_action['sparse'].shape)\n",
    "print(\"pred_action['sparse'].shape: \", pred_action['sparse'].shape)\n",
    "print(\"gt_action['dense'].shape: \", gt_action['dense'].shape)\n",
    "print(\"pred_action['dense'].shape: \", pred_action['dense'].shape)\n",
    "\n",
    "step_log = {}\n",
    "log_action_mse(step_log, 'train', pred_action, gt_action)\n",
    "print(step_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
